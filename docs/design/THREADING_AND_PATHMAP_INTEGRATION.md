# MORK and PathMap Threading Model for MeTTaTron

## Overview

This document describes MeTTaTron's threading model for MORK Space and PathMap operations, based on learnings from the Rholang Language Server integration. It covers thread safety guarantees, performance considerations, and best practices for parallel evaluation.

## Table of Contents

1. [Threading Model](#threading-model)
2. [Current Architecture](#current-architecture)
3. [Thread Safety Guarantees](#thread-safety-guarantees)
4. [Performance Characteristics](#performance-characteristics)
5. [Best Practices](#best-practices)
6. [Common Pitfalls](#common-pitfalls)
7. [Optimization Opportunities](#optimization-opportunities)
8. [Related Documentation](#related-documentation)

---

## Threading Model

### Critical Understanding

MORK's threading model is built around two key types:

1. **`SharedMappingHandle`**: Thread-safe (`Send + Sync`)
   - Can be cloned and shared across threads
   - Provides symbol interning (string ‚Üí u64 mapping)
   - Immutable once created
   - Backed by `Arc<RwLock<SymbolMap>>` internally

2. **`Space`**: NOT thread-safe (contains `Cell<u64>`)
   - Must be protected by synchronization primitives (`Mutex`, `RwLock`)
   - Contains `btm: PathMap<T>`, `sm: SharedMappingHandle`, `mmaps: HashMap<...>`
   - PathMap's `ArenaCompactTree` uses `Cell<u64>` for node IDs
   - **Cannot** be stored in `Arc<Space>` without `Mutex` or `RwLock`

### Why Space Is Not Thread-Safe

From PathMap's source code:

```rust
// PathMap's ArenaCompactTree
pub struct ArenaCompactTree<A: Allocator> {
    next_id: Cell<u64>,  // ‚ùå NOT Sync! Cell is not thread-safe
    // ...
}
```

**Result**: `Space` must be wrapped in synchronization primitives (`Arc<Mutex<Space>>` or `Arc<RwLock<Space>>`).

---

## Current Architecture

### Environment Structure

**Location**: `src/backend/environment.rs:16-50`

```rust
#[derive(Clone)]
pub struct Environment {
    /// MORK Space: primary fact database
    /// Thread-safe via Arc<Mutex<>> for parallel evaluation
    pub space: Arc<Mutex<Space>>,

    /// Rule index: Maps (head_symbol, arity) -> Vec<Rule>
    /// Thread-safe via Arc<Mutex<>> for parallel evaluation
    rule_index: Arc<Mutex<HashMap<(String, usize), Vec<Rule>>>>,

    /// Wildcard rules: Rules without clear head symbol
    /// Thread-safe via Arc<Mutex<>> for parallel evaluation
    wildcard_rules: Arc<Mutex<Vec<Rule>>>,

    /// Multiplicities: tracks rule definition counts
    /// Thread-safe via Arc<Mutex<>> for parallel evaluation
    multiplicities: Arc<Mutex<HashMap<String, usize>>>,

    /// Pattern cache: LRU cache for MORK serialization
    /// Thread-safe via Arc<Mutex<>> for parallel evaluation
    pattern_cache: Arc<Mutex<LruCache<MettaValue, Vec<u8>>>>,

    /// Fuzzy matcher: Symbol suggestions
    fuzzy_matcher: FuzzyMatcher,
}
```

### Threading Strategy

**Current**: `Arc<Mutex<Space>>` for exclusive access
- **Pros**: Simple, correct, prevents data races
- **Cons**: Serializes all Space operations (read + write)

**Alternative**: `Arc<RwLock<Space>>` for read-write distinction
- **Pros**: Multiple concurrent readers, exclusive writer
- **Cons**: More complex, potential for deadlocks if misused

### Lock Acquisition Patterns

MeTTaTron acquires locks 22 times across Environment operations:

1. **Read-Only Operations** (18 occurrences):
   - `get_type()` - Type lookup
   - `iter_rules()` - Rule iteration
   - `has_fact()` - Fact existence check
   - `has_sexpr_fact_linear()` - S-expression search
   - `get_matching_rules()` - Rule index lookup (2 locks)
   - `value_to_mork_bytes()` - MORK conversion (2 locks: space + cache)

2. **Write Operations** (4 occurrences):
   - `add_rule()` - Insert rule (space + index + multiplicities)
   - `add_to_space()` - Insert fact
   - `set_multiplicities()` - Restore from serialization

**Lock Duration**: All locks are held for short durations (microseconds to milliseconds).

---

## Thread Safety Guarantees

### What Is Thread-Safe

‚úÖ **Environment Cloning**:
```rust
let env = Environment::new();
let env2 = env.clone(); // Clones Arc pointers, shares underlying data
```

‚úÖ **Parallel Reads** (with current `Mutex`):
```rust
// These operations are safe but serialized
let space = env.space.lock().unwrap();
let rz = space.btm.read_zipper();
// ... read operations ...
```

‚úÖ **Concurrent Cache Access**:
```rust
// Pattern cache is independently locked
let bytes = env.value_to_mork_bytes(&pattern)?; // Safe across threads
```

### What Is NOT Thread-Safe

‚ùå **Bare Space Access**:
```rust
// ‚ùå WRONG: Space is not Sync
pub struct BadEnv {
    space: Arc<Space>,  // Compile error!
}
```

‚ùå **Long-Held Locks**:
```rust
// ‚ùå WRONG: Holding lock across await point
let space = env.space.lock().unwrap();
some_async_operation().await; // Deadlock risk!
// Use space here
```

‚ùå **Nested Locks Without Ordering**:
```rust
// ‚ùå WRONG: Can deadlock if lock order varies
let space = env.space.lock().unwrap();
let index = env.rule_index.lock().unwrap(); // Potential deadlock
```

---

## Performance Characteristics

### Lock Contention Analysis

**Current Workload**: MeTTaTron is read-heavy
- **Queries**: 95%+ (pattern matching, rule lookup, fact checking)
- **Updates**: <5% (rule addition, fact insertion)

**Mutex Performance**:
- Read lock: ~10-50 nanoseconds (uncontended)
- Write lock: ~10-50 nanoseconds (uncontended)
- Contended lock: ~1-100 microseconds (depending on contention)

**Potential RwLock Performance**:
- Read lock: ~15-60 nanoseconds (uncontended)
- Write lock: ~15-60 nanoseconds (uncontended)
- Multiple readers: No contention (true parallelism)
- **Speedup**: 2-5x for read-heavy parallel workloads

### PathMap Operations

From Rholang LSP benchmarks:

| Operation | Time | Complexity |
|-----------|------|------------|
| PathMap clone | O(1) | Structural sharing via Arc |
| PathMap insert | ~29¬µs | O(k) where k = path depth |
| PathMap query | ~9¬µs | O(k + m) where m = matches |
| MORK conversion | ~1-3¬µs | Per argument |
| Zipper descent | ~100ns | Per level |

**Insight**: PathMap operations are fast, but lock acquisition dominates in high-concurrency scenarios.

### Pattern Cache Performance

**Cache Hit Rate**: Expected 70-90% for typical workloads
- REPL: 80-95% (repeated patterns)
- Batch evaluation: 60-80% (some unique patterns)

**Cache Miss Penalty**: ~1-3¬µs MORK conversion
**Cache Hit Speedup**: ~3-10x (avoids conversion + Space lock)

---

## Best Practices

### 1. Minimize Lock Duration

‚úÖ **Good**:
```rust
let rules = {
    let space = env.space.lock().unwrap();
    env.iter_rules().collect::<Vec<_>>()
}; // Lock dropped here
// Process rules without holding lock
```

‚ùå **Bad**:
```rust
let space = env.space.lock().unwrap();
for rule in env.iter_rules() {
    expensive_operation(&rule); // Holds lock too long!
}
```

### 2. Use Consistent Lock Ordering

‚úÖ **Good**:
```rust
// Always acquire in order: space -> rule_index -> wildcards -> multiplicities
let space = env.space.lock().unwrap();
let index = env.rule_index.lock().unwrap();
// ... use both ...
```

‚ùå **Bad**:
```rust
// Inconsistent ordering causes deadlocks
// Thread 1: space -> index
// Thread 2: index -> space  ‚Üê Deadlock!
```

### 3. Avoid Locks in Async Context

‚úÖ **Good**:
```rust
let data = {
    let space = env.space.lock().unwrap();
    extract_data(&space)
}; // Lock dropped

async_operation(data).await; // No lock held
```

‚ùå **Bad**:
```rust
let space = env.space.lock().unwrap(); // Lock acquired
async_operation().await; // ‚ùå Lock held across await
use_space(&space);
```

### 4. Batch Operations When Possible

‚úÖ **Good**:
```rust
// Collect all rules, then release lock
let rules: Vec<Rule> = env.iter_rules().collect();
drop(space_guard);

// Process rules in parallel without holding lock
rules.par_iter().for_each(|rule| process(rule));
```

### 5. Leverage Pattern Cache

‚úÖ **Good**:
```rust
// Cache handles locking internally
let bytes = env.value_to_mork_bytes(&pattern)?; // Uses cache
```

The cache is checked before acquiring the Space lock, reducing contention.

---

## Common Pitfalls

### ‚ùå Mistake 1: Storing Space Without Synchronization

```rust
// ‚ùå WRONG: Space is not Sync
pub struct BadMatcher {
    space: Arc<Space>,  // Compile error!
}
```

**Fix**:
```rust
// ‚úÖ CORRECT: Wrap in Mutex or RwLock
pub struct GoodMatcher {
    space: Arc<Mutex<Space>>,  // Thread-safe
}
```

### ‚ùå Mistake 2: Full Trie Iteration Without Filtering

```rust
// ‚ùå WRONG: Iterates ENTIRE trie (O(n))
let space = env.space.lock().unwrap();
let mut rz = space.btm.read_zipper();
while rz.to_next_val() {
    // Check every single entry... slow!
}
```

**Fix**:
```rust
// ‚úÖ CORRECT: Navigate to prefix first (O(k + m))
let space = env.space.lock().unwrap();
let mut rz = space.btm.read_zipper();

// Descend to prefix
let prefix = b"(fibonacci ";
if rz.descend_to_existing(prefix) == prefix.len() {
    // Now iterate only matching entries
    while rz.to_next_val() {
        // Only entries with matching prefix
    }
}
```

**Performance Impact**:
- Full iteration: O(n) where n = total facts (could be 10,000+)
- Prefix filtering: O(k + m) where k = prefix depth (1-3), m = matches (1-10)
- **Speedup**: 100-1000x for sparse queries

### ‚ùå Mistake 3: Holding Lock During Expensive Computation

```rust
// ‚ùå WRONG: Holds lock during expensive operation
let space = env.space.lock().unwrap();
for rule in iter_rules(&space) {
    expensive_unification(rule); // Blocks other threads!
}
```

**Fix**:
```rust
// ‚úÖ CORRECT: Collect first, then process
let rules: Vec<Rule> = {
    let space = env.space.lock().unwrap();
    iter_rules(&space).collect()
}; // Lock dropped

// Process without holding lock
for rule in rules {
    expensive_unification(rule);
}
```

### ‚ùå Mistake 4: Ignoring Cache Opportunities

```rust
// ‚ùå SUBOPTIMAL: Bypasses cache
let space = env.space.lock().unwrap();
let bytes = metta_to_mork_bytes(&pattern, &space, &mut ctx)?;
```

**Fix**:
```rust
// ‚úÖ CORRECT: Use cache-aware method
let bytes = env.value_to_mork_bytes(&pattern)?; // Uses cache
```

---

## Optimization Opportunities

### 1. Consider RwLock for Read-Heavy Workloads

**Current**: `Arc<Mutex<Space>>`
**Alternative**: `Arc<RwLock<Space>>`

**Benefit**: Multiple concurrent readers (no blocking)
**Trade-off**: Slightly higher overhead per lock (15-20ns vs 10-15ns)

**Analysis**:
- 95%+ of operations are reads (queries, pattern matching)
- Write operations are infrequent (rule addition)
- Parallel evaluation would benefit from concurrent reads

**Recommendation**: **Consider migrating to `RwLock`** for 2-5x speedup in parallel workloads.

**Migration Pattern**:
```rust
// Before
pub space: Arc<Mutex<Space>>,

// After
pub space: Arc<RwLock<Space>>,

// Reads (no change needed)
let space = env.space.read().unwrap();

// Writes (change lock() to write())
let mut space = env.space.write().unwrap();
```

### 2. Implement Prefix-First Zipper Navigation

**Current**: Some operations use `has_fact()` with full iteration (line 541)
**Improvement**: Extract prefix and navigate before iterating

**Example**:
```rust
// Current (O(n))
pub fn has_fact(&self, atom: &str) -> bool {
    let space = self.space.lock().unwrap();
    let mut rz = space.btm.read_zipper();
    if rz.to_next_val() { return true; }
    false
}

// Improved (O(k + m))
pub fn has_fact(&self, atom: &str) -> bool {
    let space = self.space.lock().unwrap();
    let mut rz = space.btm.read_zipper();

    // Navigate to atom prefix
    let atom_bytes = atom.as_bytes();
    if rz.descend_to_existing(atom_bytes) == atom_bytes.len() {
        return rz.val().is_some();
    }
    false
}
```

**Benefit**: 100-1000x speedup for sparse queries

### 3. Parallel File Loading

**Current**: MeTTa files are loaded sequentially
**Opportunity**: Parse and convert multiple files in parallel

**Pattern** (from Rholang LSP):
```rust
use rayon::prelude::*;

pub fn load_workspace(files: Vec<PathBuf>) -> Result<Environment, String> {
    // Phase 1: Parallel parsing and MORK conversion
    let parsed: Vec<_> = files.par_iter()
        .map(|file| {
            let content = std::fs::read_to_string(file)?;
            // Each thread can parse independently
            parse_metta(&content)
        })
        .collect::<Result<Vec<_>, _>>()?;

    // Phase 2: Sequential insertion (Space requires exclusive access)
    let mut env = Environment::new();
    for ast in parsed {
        env.add_to_space(&ast);
    }

    Ok(env)
}
```

**Benefit**: 10-20x speedup for workspaces with 100+ files

### 4. Optimize Lock Granularity

**Current**: Single lock covers entire Space
**Alternative**: Fine-grained locking (not recommended due to complexity)

**Recommendation**: Keep current granularity, but use `RwLock` for read parallelism.

---

## Related Documentation

### MeTTaTron Documentation

- **[Threading Model](./THREADING_MODEL.md)**: Tokio runtime and blocking thread pool configuration
- **[CLAUDE.md](../.claude/CLAUDE.md)**: Project architecture and threading guidelines
- **[Environment API](../src/backend/environment.rs)**: Implementation details

### External References

- **[Rholang LSP MORK Integration](../../../rholang-language-server/docs/architecture/mork_pathmap_integration.md)**: Source of these learnings
- **[MORK Repository](https://github.com/trueagi-io/MORK)**: Pattern matching engine
- **[PathMap Repository](https://github.com/Adam-Vandervorst/PathMap)**: Trie-based indexing

---

## Summary

**Current State**:
‚úÖ Thread-safe via `Arc<Mutex<Space>>`
‚úÖ Correct lock acquisition patterns
‚úÖ Pattern cache reduces lock contention
‚úÖ 22 lock acquisitions, all short-duration

**Optimization Opportunities**:
1. üéØ **HIGH PRIORITY**: Migrate to `Arc<RwLock<Space>>` for 2-5x parallel read speedup
2. üéØ **HIGH PRIORITY**: Implement prefix-first zipper navigation for 100-1000x sparse query speedup
3. üéØ **MEDIUM PRIORITY**: Parallel file loading for 10-20x workspace initialization speedup
4. üéØ **LOW PRIORITY**: Profile and tune pattern cache size (currently 1000 entries)

**Key Takeaways**:
- MeTTaTron's threading model is **correct and safe**
- Lock contention is **minimal** for single-threaded workloads
- **Significant optimization potential** for parallel workloads via `RwLock`
- **Prefix-based navigation** is the biggest low-hanging fruit
- Pattern matching operations dominate, so read optimization has high ROI
